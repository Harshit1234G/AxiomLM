{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8935221,"sourceType":"datasetVersion","datasetId":5375584},{"sourceId":14849702,"sourceType":"datasetVersion","datasetId":9473726}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nimport tensorflow as tf\nimport sys\n\n# appending llm_components path to sys.path to easily import\nsys.path.append('/kaggle/input/datasets/harshit1234g/axiomlm-utils')\nimport llm_components as lc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:04:44.372403Z","iopub.execute_input":"2026-02-15T16:04:44.372694Z","iopub.status.idle":"2026-02-15T16:04:44.377547Z","shell.execute_reply.started":"2026-02-15T16:04:44.372667Z","shell.execute_reply":"2026-02-15T16:04:44.376818Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:45.242715Z","iopub.execute_input":"2026-02-15T16:04:45.243006Z","iopub.status.idle":"2026-02-15T16:04:45.936474Z","shell.execute_reply.started":"2026-02-15T16:04:45.242981Z","shell.execute_reply":"2026-02-15T16:04:45.935872Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Paths","metadata":{}},{"cell_type":"code","source":"# directories\ndirectory = Path('/kaggle/input/datasets')\ndata_dir = directory / 'vadimkurochkin'/ 'wikitext-103' / 'wikitext-103'\nutils_dir = directory / 'harshit1234g' / 'axiomlm-utils'\n\n# dataset paths\ntrain_path = data_dir / 'wiki.train.tokens'\nvalid_path = data_dir / 'wiki.valid.tokens'\ntest_path = data_dir / 'wiki.test.tokens'\n\n# tokenizer\ntokenizer_path =  utils_dir / 'sp_tokenizer.model'\n\n# Path for checkpoint directory, the reason for 2 checkpoint directories is because \n# kaggle reads from input directory, but saves in working directory\ncheckpoint_restore_dir = utils_dir / 'checkpoints'\ncheckpoint_save_dir = Path('/kaggle/working/checkpoints')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:46.117531Z","iopub.execute_input":"2026-02-15T16:04:46.117765Z","iopub.status.idle":"2026-02-15T16:04:46.122505Z","shell.execute_reply.started":"2026-02-15T16:04:46.117744Z","shell.execute_reply":"2026-02-15T16:04:46.121849Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Hyper Parameters","metadata":{}},{"cell_type":"code","source":"SEQUENCE_LEN = 256      # Context size\nSHIFT = SEQUENCE_LEN    # using shift = seq_len because the dataset is quite large\nBATCH_SIZE = 64         # previously used 128 batch size, but got OOM\nN_EMBEDS = 512\nN_HEADS = 8\nN_BLOCKS = 8\nSTEPS_PER_EPOCH = 4000\nVAL_STEPS = 200","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:46.382849Z","iopub.execute_input":"2026-02-15T16:04:46.383430Z","iopub.status.idle":"2026-02-15T16:04:46.386796Z","shell.execute_reply.started":"2026-02-15T16:04:46.383406Z","shell.execute_reply":"2026-02-15T16:04:46.386143Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"target_tokens = 600_000_000\ntoken_per_step = BATCH_SIZE * SEQUENCE_LEN\ntoken_per_chunk = STEPS_PER_EPOCH * token_per_step\ntotal_steps = round(target_tokens // token_per_step, -3)\nwarmup_steps = int(total_steps * 0.05)  # 5%\nprint(f'Total target tokens: {target_tokens:3,}')\nprint(f'Steps per epoch: {STEPS_PER_EPOCH:3,}')\nprint(f'Token per step: {token_per_step:3,}')\nprint(f'Token per chunk/epoch: {token_per_chunk:3,}')\nprint(f'Total steps for cosine decay: {total_steps:3,}')\nprint(f'Warmup steps for cosine decay: {warmup_steps:3,}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:04:47.529745Z","iopub.execute_input":"2026-02-15T16:04:47.530434Z","iopub.status.idle":"2026-02-15T16:04:47.535201Z","shell.execute_reply.started":"2026-02-15T16:04:47.530403Z","shell.execute_reply":"2026-02-15T16:04:47.534636Z"}},"outputs":[{"name":"stdout","text":"Total target tokens: 600,000,000\nSteps per epoch: 4,000\nToken per step: 16,384\nToken per chunk/epoch: 65,536,000\nTotal steps for cosine decay: 37,000\nWarmup steps for cosine decay: 1,850\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"sp = lc.load_sp_tokenizer(str(tokenizer_path))\nloader = lc.LMDatasetLoader(\n    tokenizer= sp,\n    shift= SHIFT,\n    seq_len= SEQUENCE_LEN,\n    batch_size= BATCH_SIZE,\n    shuffle_buffer= 16_000\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:48.368038Z","iopub.execute_input":"2026-02-15T16:04:48.368359Z","iopub.status.idle":"2026-02-15T16:04:48.402480Z","shell.execute_reply.started":"2026-02-15T16:04:48.368333Z","shell.execute_reply":"2026-02-15T16:04:48.401753Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_ds = loader.create(train_path, training= True)\nvalid_ds = loader.create(valid_path, training= False)\ntest_ds = loader.create(test_path, training= False)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:50.316265Z","iopub.execute_input":"2026-02-15T16:04:50.317015Z","iopub.status.idle":"2026-02-15T16:04:51.133851Z","shell.execute_reply.started":"2026-02-15T16:04:50.316988Z","shell.execute_reply":"2026-02-15T16:04:51.133287Z"},"trusted":true},"outputs":[{"name":"stderr","text":"I0000 00:00:1771171490.737045      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1771171490.742945      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for item in train_ds.take(1):\n    print(item)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T14:51:53.093916Z","iopub.execute_input":"2026-02-15T14:51:53.094500Z","iopub.status.idle":"2026-02-15T14:53:40.511225Z","shell.execute_reply.started":"2026-02-15T14:51:53.094473Z","shell.execute_reply":"2026-02-15T14:53:40.510517Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[ 1490,   493,  5492, ...,  2029,    11,    84],\n       [ 2781,  2285,    31, ...,  6534,  1135,    11],\n       [  105,    67,  3257, ..., 15919,  2468,    92],\n       ...,\n       [ 4549,    11,  7599, ...,  2194,   589,  6583],\n       [ 7125, 15920,    53, ..., 11798,   118,    11],\n       [  269,  3481,    36, ...,  3683,  2594,   433]], dtype=int32)>, <tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[  493,  5492,  1889, ...,    11,    84,     6],\n       [ 2285,    31,     8, ...,  1135,    11,  7693],\n       [   67,  3257,    84, ...,  2468,    92,   329],\n       ...,\n       [   11,  7599,    33, ...,   589,  6583,     6],\n       [15920,    53,   119, ...,   118,    11,  1749],\n       [ 3481,    36,  2159, ...,  2594,   433,     8]], dtype=int32)>)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Callbacks, Strategy & Vocab size","metadata":{}},{"cell_type":"code","source":"tensorboard_cb = tf.keras.callbacks.TensorBoard(\n    log_dir= 'logs',\n    histogram_freq= 1,\n    update_freq= 100,    # every 100 batch\n    embeddings_freq= 1\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:52.274101Z","iopub.execute_input":"2026-02-15T16:04:52.274722Z","iopub.status.idle":"2026-02-15T16:04:52.278176Z","shell.execute_reply.started":"2026-02-15T16:04:52.274693Z","shell.execute_reply":"2026-02-15T16:04:52.277542Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:52.690934Z","iopub.execute_input":"2026-02-15T16:04:52.691488Z","iopub.status.idle":"2026-02-15T16:04:52.704201Z","shell.execute_reply.started":"2026-02-15T16:04:52.691462Z","shell.execute_reply":"2026-02-15T16:04:52.703518Z"},"trusted":true},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"vocab_size = sp.get_piece_size()\nvocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:04:53.576243Z","iopub.execute_input":"2026-02-15T16:04:53.577019Z","iopub.status.idle":"2026-02-15T16:04:53.581568Z","shell.execute_reply.started":"2026-02-15T16:04:53.576989Z","shell.execute_reply":"2026-02-15T16:04:53.581014Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"16000"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Transformer Model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    # creating model\n    model = lc.GPT(\n        vocab_size= vocab_size,\n        seq_len= SEQUENCE_LEN,\n        n_embeds= N_EMBEDS,\n        n_heads= N_HEADS,\n        n_blocks= N_BLOCKS\n    )\n\n    # lr schedule\n    lr_schedule = lc.WarmupCosine(\n        base_lr= 3e-4,\n        warmup_steps= warmup_steps,\n        total_steps= total_steps\n    )\n\n    # optimizer\n    optimizer = tf.keras.optimizers.AdamW(\n        learning_rate= lr_schedule,\n        weight_decay= 0.1,\n        beta_2= 0.95,\n        clipnorm= 1.0\n    )\n    \n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits= True     # softmax is handled by loss function\n    )\n\n    # compiling\n    model.compile(\n        optimizer= optimizer,\n        loss= loss_fn,\n        metrics= [lc.Perplexity()]\n    )\n\n    # passing dummy input to build model\n    dummy = tf.zeros((1, SEQUENCE_LEN), dtype= tf.int32)\n    _ = model(dummy, training= False)\n\n    # checkpoint logic\n    checkpoint = tf.train.Checkpoint(\n        model= model,\n        optimizer= optimizer\n    )\n\n    latest_ch = tf.train.latest_checkpoint(checkpoint_restore_dir)\n    if latest_ch:\n        print('Restoring State from', latest_ch)\n        \n        optimizer.build(model.trainable_variables)\n        checkpoint.restore(latest_ch).assert_existing_objects_matched()\n        \n        print('Step:', optimizer.iterations.numpy())\n        print('LR:', lr_schedule(optimizer.iterations).numpy())\n        print('Optimizer Variables:', len(optimizer.variables))    # must be larger than 100\n\n    else:\n        print('No Checkpoint found, random initialization.')\n\n    manager = tf.train.CheckpointManager(\n        checkpoint,\n        checkpoint_save_dir,\n        max_to_keep= 3\n    )","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:04:54.289688Z","iopub.execute_input":"2026-02-15T16:04:54.289970Z","iopub.status.idle":"2026-02-15T16:05:04.474126Z","shell.execute_reply.started":"2026-02-15T16:04:54.289945Z","shell.execute_reply":"2026-02-15T16:05:04.473376Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Restoring State from /kaggle/input/datasets/harshit1234g/axiomlm-utils/checkpoints/ckpt-1\nStep: 4000\nLR: 0.0002975152\nOptimizer Variables: 185\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:05:08.211924Z","iopub.execute_input":"2026-02-15T16:05:08.212243Z","iopub.status.idle":"2026-02-15T16:05:08.232786Z","shell.execute_reply.started":"2026-02-15T16:05:08.212200Z","shell.execute_reply":"2026-02-15T16:05:08.232278Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gpt\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │     \u001b[38;5;34m8,192,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m131,072\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_2             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_3             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_4             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_5             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_6             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_7             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_16          │ ?                      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_2             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_3             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_4             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_5             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_6             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_7             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_16          │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,592,641\u001b[0m (383.73 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,592,641</span> (383.73 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m67,061,761\u001b[0m (255.82 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,061,761</span> (255.82 MB)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"history = model.fit(\n    train_ds, \n    steps_per_epoch= STEPS_PER_EPOCH,\n    epochs= 1,\n    validation_data= valid_ds,\n    validation_steps= VAL_STEPS,\n    callbacks= [tensorboard_cb]\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T16:05:09.148364Z","iopub.execute_input":"2026-02-15T16:05:09.149032Z","iopub.status.idle":"2026-02-15T17:12:59.403329Z","shell.execute_reply.started":"2026-02-15T16:05:09.149001Z","shell.execute_reply":"2026-02-15T17:12:59.402543Z"},"trusted":true},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Collective all_reduce tensors: 91 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991ms/step - loss: 4.0012 - perplexity: 56.8638","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4035s\u001b[0m 994ms/step - loss: 4.0012 - perplexity: 56.8622 - val_loss: 3.4518 - val_perplexity: 41.9133\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_loss, test_perplexity = model.evaluate(test_ds)\nprint(f'{test_loss = }\\n{test_perplexity = }')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T17:13:06.537562Z","iopub.execute_input":"2026-02-15T17:13:06.538314Z","iopub.status.idle":"2026-02-15T17:13:13.126965Z","shell.execute_reply.started":"2026-02-15T17:13:06.538281Z","shell.execute_reply":"2026-02-15T17:13:13.126273Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 348ms/step - loss: 3.5989 - perplexity: 39.7988\ntest_loss = 3.456530809402466\ntest_perplexity = 41.597496032714844\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"manager.save()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T17:13:17.562911Z","iopub.execute_input":"2026-02-15T17:13:17.563204Z","iopub.status.idle":"2026-02-15T17:13:18.224951Z","shell.execute_reply.started":"2026-02-15T17:13:17.563177Z","shell.execute_reply":"2026-02-15T17:13:18.224339Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoints/ckpt-2'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.save('axiomlm.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\n\n# creating zip of kaggle working directory to easily download it on my system\nsubprocess.run(['zip', '-r', 'working_dir.zip', '/kaggle/working'], stdout= subprocess.DEVNULL)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T17:13:20.578652Z","iopub.execute_input":"2026-02-15T17:13:20.579368Z","iopub.status.idle":"2026-02-15T17:14:01.446778Z","shell.execute_reply.started":"2026-02-15T17:13:20.579335Z","shell.execute_reply":"2026-02-15T17:14:01.446157Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['zip', '-r', 'working_dir.zip', '/kaggle/working'], returncode=0)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}