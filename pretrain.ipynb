{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:16.166225Z",
     "iopub.status.busy": "2026-02-10T16:38:16.165342Z",
     "iopub.status.idle": "2026-02-10T16:38:16.170077Z",
     "shell.execute_reply": "2026-02-10T16:38:16.169159Z",
     "shell.execute_reply.started": "2026-02-10T16:38:16.166180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "sys.path.append('/kaggle/input/axiomlm-utils')\n",
    "import llm_components as lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:16.945567Z",
     "iopub.status.busy": "2026-02-10T16:38:16.945282Z",
     "iopub.status.idle": "2026-02-10T16:38:17.812269Z",
     "shell.execute_reply": "2026-02-10T16:38:17.811528Z",
     "shell.execute_reply.started": "2026-02-10T16:38:16.945543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:17.813881Z",
     "iopub.status.busy": "2026-02-10T16:38:17.813577Z",
     "iopub.status.idle": "2026-02-10T16:38:17.825254Z",
     "shell.execute_reply": "2026-02-10T16:38:17.824574Z",
     "shell.execute_reply.started": "2026-02-10T16:38:17.813857Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "directory = Path('/kaggle/input')\n",
    "data_dir = directory / 'wikitext-103' / 'wikitext-103'\n",
    "train_path = data_dir / 'wiki.train.tokens'\n",
    "valid_path = data_dir / 'wiki.valid.tokens'\n",
    "test_path = data_dir / 'wiki.test.tokens'\n",
    "tokenizer_path = directory / 'axiom-utils' / 'sp_tokenizer.model'\n",
    "# the reason for 2 checkpoint directories is because \n",
    "# kaggle reads from input directory, but saves in working directory\n",
    "checkpoint_restore_dir = directory / 'axiom-utils' / 'checkpoints'\n",
    "checkpoint_save_dir = Path('/kaggle/working/checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:18.242254Z",
     "iopub.status.busy": "2026-02-10T16:38:18.241600Z",
     "iopub.status.idle": "2026-02-10T16:38:18.245880Z",
     "shell.execute_reply": "2026-02-10T16:38:18.245229Z",
     "shell.execute_reply.started": "2026-02-10T16:38:18.242225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 256    # Context size\n",
    "SHIFT = 16\n",
    "BATCH_SIZE = 64\n",
    "N_EMBEDS = 512\n",
    "N_HEADS = 8\n",
    "N_BLOCKS = 8\n",
    "STEPS_PER_EPOCH = 3000\n",
    "VAL_STEPS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:19.194959Z",
     "iopub.status.busy": "2026-02-10T16:38:19.194215Z",
     "iopub.status.idle": "2026-02-10T16:38:19.223485Z",
     "shell.execute_reply": "2026-02-10T16:38:19.222636Z",
     "shell.execute_reply.started": "2026-02-10T16:38:19.194930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sp = lc.load_sp_tokenizer(str(tokenizer_path))\n",
    "loader = lc.LMDatasetLoader(\n",
    "    tokenizer= sp,\n",
    "    shift= SHIFT,\n",
    "    seq_len= SEQUENCE_LEN,\n",
    "    batch_size= BATCH_SIZE,\n",
    "    shuffle_buffer= 50_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:20.226704Z",
     "iopub.status.busy": "2026-02-10T16:38:20.226358Z",
     "iopub.status.idle": "2026-02-10T16:38:21.085719Z",
     "shell.execute_reply": "2026-02-10T16:38:21.084947Z",
     "shell.execute_reply.started": "2026-02-10T16:38:20.226677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770741500.659343      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1770741500.665574      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_ds = loader.create(train_path, training= True)\n",
    "valid_ds = loader.create(valid_path, training= False)\n",
    "test_ds = loader.create(test_path, training= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:24.103696Z",
     "iopub.status.busy": "2026-02-10T16:38:24.103094Z",
     "iopub.status.idle": "2026-02-10T16:38:47.322193Z",
     "shell.execute_reply": "2026-02-10T16:38:47.321333Z",
     "shell.execute_reply.started": "2026-02-10T16:38:24.103667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
      "array([[  165,  1259,    37, ...,  3859,  7176,    37],\n",
      "       [ 9113,   264,    36, ...,    67,  1273,   103],\n",
      "       [ 4427,   124, 10922, ...,  3037,    53,  2873],\n",
      "       ...,\n",
      "       [11966,  7118,    92, ..., 15919,    11,  7671],\n",
      "       [   37,  4855,  1917, ...,   783,    36,  4593],\n",
      "       [    8,   265,  1421, ...,    11,  6958,  4723]], dtype=int32)>, <tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
      "array([[ 1259,    37,   143, ...,  7176,    37,   108],\n",
      "       [  264,    36,    31, ...,  1273,   103, 14600],\n",
      "       [  124, 10922,  2238, ...,    53,  2873,   247],\n",
      "       ...,\n",
      "       [ 7118,    92,     6, ...,    11,  7671,  1872],\n",
      "       [ 4855,  1917,    11, ...,    36,  4593,  2010],\n",
      "       [  265,  1421,    29, ...,  6958,  4723,   148]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for item in train_ds.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy, callbacks, & some required calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:47.323984Z",
     "iopub.status.busy": "2026-02-10T16:38:47.323640Z",
     "iopub.status.idle": "2026-02-10T16:38:47.329100Z",
     "shell.execute_reply": "2026-02-10T16:38:47.328419Z",
     "shell.execute_reply.started": "2026-02-10T16:38:47.323962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = sp.get_piece_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:47.330244Z",
     "iopub.status.busy": "2026-02-10T16:38:47.329944Z",
     "iopub.status.idle": "2026-02-10T16:38:47.351667Z",
     "shell.execute_reply": "2026-02-10T16:38:47.351147Z",
     "shell.execute_reply.started": "2026-02-10T16:38:47.330207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:47.353274Z",
     "iopub.status.busy": "2026-02-10T16:38:47.353045Z",
     "iopub.status.idle": "2026-02-10T16:38:47.356978Z",
     "shell.execute_reply": "2026-02-10T16:38:47.356180Z",
     "shell.execute_reply.started": "2026-02-10T16:38:47.353254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir= 'logs',\n",
    "    histogram_freq= 1,\n",
    "    update_freq= 100,    # every 100 batch\n",
    "    embeddings_freq= 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:47.358278Z",
     "iopub.status.busy": "2026-02-10T16:38:47.357966Z",
     "iopub.status.idle": "2026-02-10T16:38:47.369186Z",
     "shell.execute_reply": "2026-02-10T16:38:47.368631Z",
     "shell.execute_reply.started": "2026-02-10T16:38:47.358246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total target tokens: 500,000,000\n",
      "Steps per epoch: 3,000\n",
      "Token per step: 16,384\n",
      "Token per chunk/epoch: 49,152,000\n",
      "Total steps for cosine decay: 30,517\n",
      "Warmup steps for cosine decay: 1,525\n"
     ]
    }
   ],
   "source": [
    "target_tokens = 500_000_000\n",
    "steps_per_epoch = 3000\n",
    "token_per_step = BATCH_SIZE * SEQUENCE_LEN\n",
    "token_per_chunk = steps_per_epoch * token_per_step\n",
    "total_steps = target_tokens // token_per_step\n",
    "warmup_steps = int(total_steps * 0.05)  # 5%\n",
    "print(f'Total target tokens: {target_tokens:3,}')\n",
    "print(f'Steps per epoch: {steps_per_epoch:3,}')\n",
    "print(f'Token per step: {token_per_step:3,}')\n",
    "print(f'Token per chunk/epoch: {token_per_chunk:3,}')\n",
    "print(f'Total steps for cosine decay: {total_steps:3,}')\n",
    "print(f'Warmup steps for cosine decay: {warmup_steps:3,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:47.370460Z",
     "iopub.status.busy": "2026-02-10T16:38:47.370152Z",
     "iopub.status.idle": "2026-02-10T16:38:53.584937Z",
     "shell.execute_reply": "2026-02-10T16:38:53.584208Z",
     "shell.execute_reply.started": "2026-02-10T16:38:47.370411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring State from /kaggle/input/axiom-utils/checkpoints/ckpt-2\n",
      "Step: 6000 LR: 0.0002844365\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # creating model\n",
    "    model = lc.GPT(\n",
    "        vocab_size= vocab_size,\n",
    "        seq_len= SEQUENCE_LEN,\n",
    "        n_embeds= N_EMBEDS,\n",
    "        n_heads= N_HEADS,\n",
    "        n_blocks= N_BLOCKS\n",
    "    )\n",
    "\n",
    "    # lr schedule\n",
    "    lr_schedule = lc.WarmupCosine(\n",
    "        base_lr= 3e-4,\n",
    "        warmup_steps= warmup_steps,\n",
    "        total_steps= total_steps\n",
    "    )\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate= lr_schedule,\n",
    "        weight_decay= 0.01,\n",
    "        beta_2= 0.95,\n",
    "        clipnorm= 1.0\n",
    "    )\n",
    "    \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits= True     # softmax is handled by loss function\n",
    "    )\n",
    "\n",
    "    # compiling\n",
    "    model.compile(\n",
    "        optimizer= optimizer,\n",
    "        loss= loss_fn,\n",
    "        metrics= [lc.Perplexity()]\n",
    "    )\n",
    "\n",
    "    # passing dummy input to build model\n",
    "    dummy = tf.zeros((1, SEQUENCE_LEN), dtype= tf.int32)\n",
    "    _ = model(dummy, training= False)\n",
    "\n",
    "    # checkpoint logic\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        model= model,\n",
    "        optimizer= optimizer\n",
    "    )\n",
    "\n",
    "    latest_ch = tf.train.latest_checkpoint(checkpoint_restore_dir)\n",
    "    if latest_ch:\n",
    "        print('Restoring State from', latest_ch)\n",
    "        checkpoint.restore(latest_ch).expect_partial()\n",
    "        print(\n",
    "            'Step:', optimizer.iterations.numpy(),\n",
    "            'LR:', lr_schedule(optimizer.iterations).numpy()\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print('No Checkpoint found, random initialization.')\n",
    "\n",
    "    manager = tf.train.CheckpointManager(\n",
    "        checkpoint,\n",
    "        checkpoint_save_dir,\n",
    "        max_to_keep= 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:38:59.122057Z",
     "iopub.status.busy": "2026-02-10T16:38:59.121317Z",
     "iopub.status.idle": "2026-02-10T16:38:59.142257Z",
     "shell.execute_reply": "2026-02-10T16:38:59.141663Z",
     "shell.execute_reply.started": "2026-02-10T16:38:59.122026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │     \u001b[38;5;34m8,192,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m131,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block               │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ ?                      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T16:39:00.153742Z",
     "iopub.status.busy": "2026-02-10T16:39:00.153103Z",
     "iopub.status.idle": "2026-02-10T17:29:15.290178Z",
     "shell.execute_reply": "2026-02-10T17:29:15.289422Z",
     "shell.execute_reply.started": "2026-02-10T16:39:00.153692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 91 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n",
      "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2988s\u001b[0m 979ms/step - loss: 4.4875 - perplexity: 1984.5010 - val_loss: 5.7229 - val_perplexity: 330.3592\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds, \n",
    "    steps_per_epoch= steps_per_epoch,\n",
    "    epochs= 1,\n",
    "    validation_data= valid_ds,\n",
    "    validation_steps= VAL_STEPS,\n",
    "    callbacks= [tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T17:29:15.291842Z",
     "iopub.status.busy": "2026-02-10T17:29:15.291544Z",
     "iopub.status.idle": "2026-02-10T17:30:57.169862Z",
     "shell.execute_reply": "2026-02-10T17:30:57.169160Z",
     "shell.execute_reply.started": "2026-02-10T17:29:15.291819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 360ms/step - loss: 5.5952 - perplexity: 301.0281\n",
      "test_loss = 5.699486255645752\n",
      "test_perplexity = 338.4040832519531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_perplexity = model.evaluate(test_ds)\n",
    "print(f'{test_loss = }\\n{test_perplexity = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T17:30:57.171076Z",
     "iopub.status.busy": "2026-02-10T17:30:57.170779Z",
     "iopub.status.idle": "2026-02-10T17:30:57.966049Z",
     "shell.execute_reply": "2026-02-10T17:30:57.965275Z",
     "shell.execute_reply.started": "2026-02-10T17:30:57.171050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/checkpoints/ckpt-3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T17:30:57.967780Z",
     "iopub.status.busy": "2026-02-10T17:30:57.967502Z",
     "iopub.status.idle": "2026-02-10T17:31:42.497102Z",
     "shell.execute_reply": "2026-02-10T17:31:42.496279Z",
     "shell.execute_reply.started": "2026-02-10T17:30:57.967746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['zip', '-r', 'working_dir.zip', '/kaggle/working'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run(['zip', '-r', 'working_dir.zip', '/kaggle/working'], stdout= subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5375584,
     "sourceId": 8935221,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9428670,
     "sourceId": 14798645,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "axiomlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
