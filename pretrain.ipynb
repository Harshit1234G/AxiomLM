{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8935221,"sourceType":"datasetVersion","datasetId":5375584},{"sourceId":14846806,"sourceType":"datasetVersion","datasetId":9473726}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nimport tensorflow as tf\nimport sys\n\n# appending llm_components path to sys.path to easily import\nsys.path.append('/kaggle/input/datasets/harshit1234g/axiomlm-utils')\nimport llm_components as lc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T15:00:24.895435Z","iopub.execute_input":"2026-02-15T15:00:24.895859Z","iopub.status.idle":"2026-02-15T15:00:24.900650Z","shell.execute_reply.started":"2026-02-15T15:00:24.895831Z","shell.execute_reply":"2026-02-15T15:00:24.899979Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:25.223901Z","iopub.execute_input":"2026-02-15T15:00:25.224162Z","iopub.status.idle":"2026-02-15T15:00:25.914719Z","shell.execute_reply.started":"2026-02-15T15:00:25.224114Z","shell.execute_reply":"2026-02-15T15:00:25.914050Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Paths","metadata":{}},{"cell_type":"code","source":"# directories\ndirectory = Path('/kaggle/input/datasets')\ndata_dir = directory / 'vadimkurochkin'/ 'wikitext-103' / 'wikitext-103'\nutils_dir = directory / 'harshit1234g' / 'axiomlm-utils'\n\n# dataset paths\ntrain_path = data_dir / 'wiki.train.tokens'\nvalid_path = data_dir / 'wiki.valid.tokens'\ntest_path = data_dir / 'wiki.test.tokens'\n\n# tokenizer\ntokenizer_path =  utils_dir / 'sp_tokenizer.model'\n\n# Path for checkpoint directory, the reason for 2 checkpoint directories is because \n# kaggle reads from input directory, but saves in working directory\ncheckpoint_restore_dir = utils_dir / 'checkpoints'\ncheckpoint_save_dir = Path('/kaggle/working/checkpoints')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:25.915977Z","iopub.execute_input":"2026-02-15T15:00:25.916262Z","iopub.status.idle":"2026-02-15T15:00:25.925930Z","shell.execute_reply.started":"2026-02-15T15:00:25.916241Z","shell.execute_reply":"2026-02-15T15:00:25.925397Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Hyper Parameters","metadata":{}},{"cell_type":"code","source":"SEQUENCE_LEN = 256      # Context size\nSHIFT = SEQUENCE_LEN    # using shift = seq_len because the dataset is quite large\nBATCH_SIZE = 64         # previously used 128 batch size, but got OOM\nN_EMBEDS = 512\nN_HEADS = 8\nN_BLOCKS = 8\nSTEPS_PER_EPOCH = 4000\nVAL_STEPS = 200","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:27.563608Z","iopub.execute_input":"2026-02-15T15:00:27.564269Z","iopub.status.idle":"2026-02-15T15:00:27.567773Z","shell.execute_reply.started":"2026-02-15T15:00:27.564243Z","shell.execute_reply":"2026-02-15T15:00:27.567177Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"target_tokens = 600_000_000\ntoken_per_step = BATCH_SIZE * SEQUENCE_LEN\ntoken_per_chunk = STEPS_PER_EPOCH * token_per_step\ntotal_steps = round(target_tokens // token_per_step, -3)\nwarmup_steps = int(total_steps * 0.05)  # 5%\nprint(f'Total target tokens: {target_tokens:3,}')\nprint(f'Steps per epoch: {STEPS_PER_EPOCH:3,}')\nprint(f'Token per step: {token_per_step:3,}')\nprint(f'Token per chunk/epoch: {token_per_chunk:3,}')\nprint(f'Total steps for cosine decay: {total_steps:3,}')\nprint(f'Warmup steps for cosine decay: {warmup_steps:3,}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T15:00:28.816595Z","iopub.execute_input":"2026-02-15T15:00:28.817226Z","iopub.status.idle":"2026-02-15T15:00:28.821950Z","shell.execute_reply.started":"2026-02-15T15:00:28.817201Z","shell.execute_reply":"2026-02-15T15:00:28.821349Z"}},"outputs":[{"name":"stdout","text":"Total target tokens: 600,000,000\nSteps per epoch: 4,000\nToken per step: 16,384\nToken per chunk/epoch: 65,536,000\nTotal steps for cosine decay: 37,000\nWarmup steps for cosine decay: 1,850\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"sp = lc.load_sp_tokenizer(str(tokenizer_path))\nloader = lc.LMDatasetLoader(\n    tokenizer= sp,\n    shift= SHIFT,\n    seq_len= SEQUENCE_LEN,\n    batch_size= BATCH_SIZE,\n    shuffle_buffer= 16_000\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:30.396506Z","iopub.execute_input":"2026-02-15T15:00:30.397066Z","iopub.status.idle":"2026-02-15T15:00:30.427418Z","shell.execute_reply.started":"2026-02-15T15:00:30.397041Z","shell.execute_reply":"2026-02-15T15:00:30.426816Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_ds = loader.create(train_path, training= True)\nvalid_ds = loader.create(valid_path, training= False)\ntest_ds = loader.create(test_path, training= False)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:30.996614Z","iopub.execute_input":"2026-02-15T15:00:30.997035Z","iopub.status.idle":"2026-02-15T15:00:31.796885Z","shell.execute_reply.started":"2026-02-15T15:00:30.997014Z","shell.execute_reply":"2026-02-15T15:00:31.796350Z"},"trusted":true},"outputs":[{"name":"stderr","text":"I0000 00:00:1771167631.416308      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1771167631.419016      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for item in train_ds.take(1):\n    print(item)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T14:51:53.093916Z","iopub.execute_input":"2026-02-15T14:51:53.094500Z","iopub.status.idle":"2026-02-15T14:53:40.511225Z","shell.execute_reply.started":"2026-02-15T14:51:53.094473Z","shell.execute_reply":"2026-02-15T14:53:40.510517Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[ 1490,   493,  5492, ...,  2029,    11,    84],\n       [ 2781,  2285,    31, ...,  6534,  1135,    11],\n       [  105,    67,  3257, ..., 15919,  2468,    92],\n       ...,\n       [ 4549,    11,  7599, ...,  2194,   589,  6583],\n       [ 7125, 15920,    53, ..., 11798,   118,    11],\n       [  269,  3481,    36, ...,  3683,  2594,   433]], dtype=int32)>, <tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[  493,  5492,  1889, ...,    11,    84,     6],\n       [ 2285,    31,     8, ...,  1135,    11,  7693],\n       [   67,  3257,    84, ...,  2468,    92,   329],\n       ...,\n       [   11,  7599,    33, ...,   589,  6583,     6],\n       [15920,    53,   119, ...,   118,    11,  1749],\n       [ 3481,    36,  2159, ...,  2594,   433,     8]], dtype=int32)>)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Callbacks, Strategy & Vocab size","metadata":{}},{"cell_type":"code","source":"tensorboard_cb = tf.keras.callbacks.TensorBoard(\n    log_dir= 'logs',\n    histogram_freq= 1,\n    update_freq= 100,    # every 100 batch\n    embeddings_freq= 1\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:35.182897Z","iopub.execute_input":"2026-02-15T15:00:35.183531Z","iopub.status.idle":"2026-02-15T15:00:35.187029Z","shell.execute_reply.started":"2026-02-15T15:00:35.183504Z","shell.execute_reply":"2026-02-15T15:00:35.186274Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:35.341450Z","iopub.execute_input":"2026-02-15T15:00:35.341848Z","iopub.status.idle":"2026-02-15T15:00:35.353666Z","shell.execute_reply.started":"2026-02-15T15:00:35.341827Z","shell.execute_reply":"2026-02-15T15:00:35.353053Z"},"trusted":true},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"vocab_size = sp.get_piece_size()\nvocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T15:00:35.477602Z","iopub.execute_input":"2026-02-15T15:00:35.477794Z","iopub.status.idle":"2026-02-15T15:00:35.482234Z","shell.execute_reply.started":"2026-02-15T15:00:35.477777Z","shell.execute_reply":"2026-02-15T15:00:35.481662Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"16000"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Transformer Model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    # creating model\n    model = lc.GPT(\n        vocab_size= vocab_size,\n        seq_len= SEQUENCE_LEN,\n        n_embeds= N_EMBEDS,\n        n_heads= N_HEADS,\n        n_blocks= N_BLOCKS\n    )\n\n    # lr schedule\n    lr_schedule = lc.WarmupCosine(\n        base_lr= 3e-4,\n        warmup_steps= warmup_steps,\n        total_steps= total_steps\n    )\n\n    # optimizer\n    optimizer = tf.keras.optimizers.AdamW(\n        learning_rate= lr_schedule,\n        weight_decay= 0.1,\n        beta_2= 0.95,\n        clipnorm= 1.0\n    )\n    \n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits= True     # softmax is handled by loss function\n    )\n\n    # compiling\n    model.compile(\n        optimizer= optimizer,\n        loss= loss_fn,\n        metrics= [lc.Perplexity()]\n    )\n\n    # passing dummy input to build model\n    dummy = tf.zeros((1, SEQUENCE_LEN), dtype= tf.int32)\n    _ = model(dummy, training= False)\n\n    # checkpoint logic\n    checkpoint = tf.train.Checkpoint(\n        model= model,\n        optimizer= optimizer\n    )\n\n    latest_ch = tf.train.latest_checkpoint(checkpoint_restore_dir)\n    if latest_ch:\n        print('Restoring State from', latest_ch)\n        \n        optimizer.build(model.trainable_variables)\n        checkpoint.restore(latest_ch).assert_existing_objects_matched()\n        \n        print('Step:', optimizer.iterations.numpy())\n        print('LR:', lr_schedule(optimizer.iterations).numpy())\n        print('Optimizer Variables:', len(optimizer.variables))    # must be larger than 100\n\n    else:\n        print('No Checkpoint found, random initialization.')\n\n    manager = tf.train.CheckpointManager(\n        checkpoint,\n        checkpoint_save_dir,\n        max_to_keep= 3\n    )","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:36.799274Z","iopub.execute_input":"2026-02-15T15:00:36.799523Z","iopub.status.idle":"2026-02-15T15:00:41.965416Z","shell.execute_reply.started":"2026-02-15T15:00:36.799502Z","shell.execute_reply":"2026-02-15T15:00:41.964683Z"},"trusted":true},"outputs":[{"name":"stdout","text":"No Checkpoint found, random initialization.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:41.966714Z","iopub.execute_input":"2026-02-15T15:00:41.966942Z","iopub.status.idle":"2026-02-15T15:00:41.986038Z","shell.execute_reply.started":"2026-02-15T15:00:41.966923Z","shell.execute_reply":"2026-02-15T15:00:41.985387Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gpt\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │     \u001b[38;5;34m8,192,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m131,072\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_2             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_3             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_4             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_5             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_6             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_7             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_16          │ ?                      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_1             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_2             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_3             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_4             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_5             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_6             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_7             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_16          │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"history = model.fit(\n    train_ds, \n    steps_per_epoch= STEPS_PER_EPOCH,\n    epochs= 1,\n    validation_data= valid_ds,\n    validation_steps= VAL_STEPS,\n    callbacks= [tensorboard_cb]\n)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:00:45.668394Z","iopub.execute_input":"2026-02-15T15:00:45.668685Z","iopub.status.idle":"2026-02-15T15:58:56.086415Z","shell.execute_reply.started":"2026-02-15T15:00:45.668663Z","shell.execute_reply":"2026-02-15T15:58:56.085705Z"},"trusted":true},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Collective all_reduce tensors: 91 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - loss: 6.3496 - perplexity: 1223.3568","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4000/4000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3456s\u001b[0m 849ms/step - loss: 6.3493 - perplexity: 1223.1010 - val_loss: 3.8366 - val_perplexity: 63.5602\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"test_loss, test_perplexity = model.evaluate(test_ds)\nprint(f'{test_loss = }\\n{test_perplexity = }')","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:59:07.386685Z","iopub.execute_input":"2026-02-15T15:59:07.387326Z","iopub.status.idle":"2026-02-15T15:59:13.077435Z","shell.execute_reply.started":"2026-02-15T15:59:07.387298Z","shell.execute_reply":"2026-02-15T15:59:13.076739Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - loss: 3.9901 - perplexity: 59.3620\ntest_loss = 3.829296588897705\ntest_perplexity = 62.19420623779297\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"manager.save()","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:59:13.078540Z","iopub.execute_input":"2026-02-15T15:59:13.078756Z","iopub.status.idle":"2026-02-15T15:59:13.819245Z","shell.execute_reply.started":"2026-02-15T15:59:13.078735Z","shell.execute_reply":"2026-02-15T15:59:13.818688Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoints/ckpt-1'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"model.save('axiomlm.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\n\n# creating zip of kaggle working directory to easily download it on my system\nsubprocess.run(['zip', '-r', 'working_dir.zip', '/kaggle/working'], stdout= subprocess.DEVNULL)","metadata":{"execution":{"iopub.status.busy":"2026-02-15T15:59:17.201184Z","iopub.execute_input":"2026-02-15T15:59:17.201987Z","iopub.status.idle":"2026-02-15T15:59:58.326988Z","shell.execute_reply.started":"2026-02-15T15:59:17.201951Z","shell.execute_reply":"2026-02-15T15:59:58.326376Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['zip', '-r', 'working_dir.zip', '/kaggle/working'], returncode=0)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}