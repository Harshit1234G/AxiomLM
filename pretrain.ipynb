{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8935221,"sourceType":"datasetVersion","datasetId":5375584},{"sourceId":14797891,"sourceType":"datasetVersion","datasetId":9428670}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nimport tensorflow as tf\nimport sys\n\nsys.path.append('/kaggle/input/axiom-utils')\nimport llm_components as lc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:49.652368Z","iopub.execute_input":"2026-02-10T15:31:49.652651Z","iopub.status.idle":"2026-02-10T15:31:49.657485Z","shell.execute_reply.started":"2026-02-10T15:31:49.652626Z","shell.execute_reply":"2026-02-10T15:31:49.656781Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:50.057725Z","iopub.execute_input":"2026-02-10T15:31:50.058174Z","iopub.status.idle":"2026-02-10T15:31:51.487985Z","shell.execute_reply.started":"2026-02-10T15:31:50.058149Z","shell.execute_reply":"2026-02-10T15:31:51.487239Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Paths","metadata":{}},{"cell_type":"code","source":"directory = Path('/kaggle/input')\ndata_dir = directory / 'wikitext-103' / 'wikitext-103'\ntrain_path = data_dir / 'wiki.train.tokens'\nvalid_path = data_dir / 'wiki.valid.tokens'\ntest_path = data_dir / 'wiki.test.tokens'\ntokenizer_path = directory / 'axiom-utils' / 'sp_tokenizer.model'\n# the reason for 2 checkpoint directories is because \n# kaggle reads from input directory, but saves in working directory\ncheckpoint_restore_dir = directory / 'axiom-utils' / 'checkpoints'\ncheckpoint_save_dir = Path('/kaggle/working/checkpoints')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:51.489486Z","iopub.execute_input":"2026-02-10T15:31:51.489729Z","iopub.status.idle":"2026-02-10T15:31:51.501713Z","shell.execute_reply.started":"2026-02-10T15:31:51.489709Z","shell.execute_reply":"2026-02-10T15:31:51.501202Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Hyper Parameters","metadata":{}},{"cell_type":"code","source":"SEQUENCE_LEN = 256    # Context size\nSHIFT = 16\nBATCH_SIZE = 64\nN_EMBEDS = 512\nN_HEADS = 8\nN_BLOCKS = 8\nSTEPS_PER_EPOCH = 3000\nVAL_STEPS = 200","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:51.502659Z","iopub.execute_input":"2026-02-10T15:31:51.502891Z","iopub.status.idle":"2026-02-10T15:31:51.515645Z","shell.execute_reply.started":"2026-02-10T15:31:51.502872Z","shell.execute_reply":"2026-02-10T15:31:51.515052Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"sp = lc.load_sp_tokenizer(str(tokenizer_path))\nloader = lc.LMDatasetLoader(\n    tokenizer= sp,\n    shift= SHIFT,\n    seq_len= SEQUENCE_LEN,\n    batch_size= BATCH_SIZE,\n    shuffle_buffer= 50_000\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:52.496277Z","iopub.execute_input":"2026-02-10T15:31:52.496799Z","iopub.status.idle":"2026-02-10T15:31:52.549135Z","shell.execute_reply.started":"2026-02-10T15:31:52.496776Z","shell.execute_reply":"2026-02-10T15:31:52.548343Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_ds = loader.create(train_path, training= True)\nvalid_ds = loader.create(valid_path, training= False)\ntest_ds = loader.create(test_path, training= False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:53.281236Z","iopub.execute_input":"2026-02-10T15:31:53.281563Z","iopub.status.idle":"2026-02-10T15:31:54.125548Z","shell.execute_reply.started":"2026-02-10T15:31:53.281540Z","shell.execute_reply":"2026-02-10T15:31:54.124848Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1770737513.716235      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1770737513.722090      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"for item in train_ds.take(1):\n    print(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:12:49.587926Z","iopub.execute_input":"2026-02-10T15:12:49.588236Z","iopub.status.idle":"2026-02-10T15:13:11.687408Z","shell.execute_reply.started":"2026-02-10T15:12:49.588205Z","shell.execute_reply":"2026-02-10T15:13:11.686613Z"}},"outputs":[{"name":"stdout","text":"(<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[  120,  8089,   113, ..., 15914,     0,  2149],\n       [ 1623,    19,   396, ...,  4587,   120,  1926],\n       [  949,   579,    11, ...,    33,     6, 10066],\n       ...,\n       [15917,    53,    11, ...,   185,    16,   673],\n       [   29,  1225,   305, ...,  3190,   370,  3119],\n       [15922,  2678,   869, ...,  5005,    11,    54]], dtype=int32)>, <tf.Tensor: shape=(64, 256), dtype=int32, numpy=\narray([[ 8089,   113,  7085, ...,     0,  2149,     0],\n       [   19,   396,  1091, ...,   120,  1926,    53],\n       [  579,    11,     8, ...,     6, 10066,  3137],\n       ...,\n       [   53,    11,    46, ...,    16,   673,   245],\n       [ 1225,   305,   214, ...,   370,  3119, 12033],\n       [ 2678,   869,    29, ...,    11,    54,   340]], dtype=int32)>)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Strategy, callbacks, & some required calculations","metadata":{}},{"cell_type":"code","source":"vocab_size = sp.get_piece_size()\nvocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:55.232960Z","iopub.execute_input":"2026-02-10T15:31:55.233296Z","iopub.status.idle":"2026-02-10T15:31:55.238470Z","shell.execute_reply.started":"2026-02-10T15:31:55.233245Z","shell.execute_reply":"2026-02-10T15:31:55.237738Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"16000"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:55.398808Z","iopub.execute_input":"2026-02-10T15:31:55.399384Z","iopub.status.idle":"2026-02-10T15:31:55.413927Z","shell.execute_reply.started":"2026-02-10T15:31:55.399356Z","shell.execute_reply":"2026-02-10T15:31:55.413240Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"tensorboard_cb = tf.keras.callbacks.TensorBoard(\n    log_dir= 'logs',\n    histogram_freq= 1,\n    update_freq= 100,    # every 100 batch\n    embeddings_freq= 1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:56.440904Z","iopub.execute_input":"2026-02-10T15:31:56.441735Z","iopub.status.idle":"2026-02-10T15:31:56.445397Z","shell.execute_reply.started":"2026-02-10T15:31:56.441705Z","shell.execute_reply":"2026-02-10T15:31:56.444597Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"target_tokens = 500_000_000\nsteps_per_epoch = 3000\ntoken_per_step = BATCH_SIZE * SEQUENCE_LEN\ntoken_per_chunk = steps_per_epoch * token_per_step\ntotal_steps = target_tokens // token_per_step\nwarmup_steps = int(total_steps * 0.05)  # 5%\nprint(f'Total target tokens: {target_tokens:3,}')\nprint(f'Steps per epoch: {steps_per_epoch:3,}')\nprint(f'Token per step: {token_per_step:3,}')\nprint(f'Token per chunk/epoch: {token_per_chunk:3,}')\nprint(f'Total steps for cosine decay: {total_steps:3,}')\nprint(f'Warmup steps for cosine decay: {warmup_steps:3,}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:31:56.604464Z","iopub.execute_input":"2026-02-10T15:31:56.604730Z","iopub.status.idle":"2026-02-10T15:31:56.609959Z","shell.execute_reply.started":"2026-02-10T15:31:56.604710Z","shell.execute_reply":"2026-02-10T15:31:56.609169Z"}},"outputs":[{"name":"stdout","text":"Total target tokens: 500,000,000\nSteps per epoch: 3,000\nToken per step: 16,384\nToken per chunk/epoch: 49,152,000\nTotal steps for cosine decay: 30,517\nWarmup steps for cosine decay: 1,525\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Transformer Model","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    # creating model\n    model = lc.GPT(\n        vocab_size= vocab_size,\n        seq_len= SEQUENCE_LEN,\n        n_embeds= N_EMBEDS,\n        n_heads= N_HEADS,\n        n_blocks= N_BLOCKS\n    )\n\n    # lr schedule\n    lr_schedule = lc.WarmupCosine(\n        base_lr= 3e-4,\n        warmup_steps= warmup_steps,\n        total_steps= total_steps\n    )\n\n    # optimizer\n    optimizer = tf.keras.optimizers.AdamW(\n        learning_rate= lr_schedule,\n        weight_decay= 0.01,\n        beta_2= 0.95,\n        clipnorm= 1.0\n    )\n    \n    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits= True     # softmax is handled by loss function\n    )\n\n    # compiling\n    model.compile(\n        optimizer= optimizer,\n        loss= loss_fn,\n        metrics= [lc.Perplexity()]\n    )\n\n    # passing dummy input to build model\n    dummy = tf.zeros((1, SEQUENCE_LEN), dtype= tf.int32)\n    _ = model(dummy, training= False)\n\n    # checkpoint logic\n    checkpoint = tf.train.Checkpoint(\n        model= model,\n        optimizer= optimizer\n    )\n\n    latest_ch = tf.train.latest_checkpoint(checkpoint_restore_dir)\n    if latest_ch:\n        print('Restoring State from', latest_ch)\n        checkpoint.restore(latest_ch).expect_partial()\n        print(\n            'Step:', optimizer.iterations.numpy(),\n            'LR:', lr_schedule(optimizer.iterations).numpy()\n        )\n\n    else:\n        print('No Checkpoint found, random initialization.')\n\n    manager = tf.train.CheckpointManager(\n        checkpoint,\n        checkpoint_save_dir,\n        max_to_keep= 1\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:34:38.218371Z","iopub.execute_input":"2026-02-10T15:34:38.219134Z","iopub.status.idle":"2026-02-10T15:34:40.192609Z","shell.execute_reply.started":"2026-02-10T15:34:38.219106Z","shell.execute_reply":"2026-02-10T15:34:40.191797Z"}},"outputs":[{"name":"stdout","text":"Restoring State from /kaggle/input/axiom-utils/checkpoints/ckpt-1\nStep: 3000 LR: 0.00029827928\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:34:43.501087Z","iopub.execute_input":"2026-02-10T15:34:43.501491Z","iopub.status.idle":"2026-02-10T15:34:43.518941Z","shell.execute_reply.started":"2026-02-10T15:34:43.501464Z","shell.execute_reply":"2026-02-10T15:34:43.518402Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gpt_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)          │     \u001b[38;5;34m8,192,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │       \u001b[38;5;34m131,072\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_8             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_9             │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_10            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_11            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_12            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_13            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_14            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_15            │ ?                      │     \u001b[38;5;34m3,150,848\u001b[0m │\n│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_33          │ ?                      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_8             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_9             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_10            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_11            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_12            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_13            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_14            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_block_15            │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,150,848</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ layer_normalization_33          │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,530,880\u001b[0m (127.91 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,530,880</span> (127.91 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"history = model.fit(\n    train_ds, \n    steps_per_epoch= steps_per_epoch,\n    epochs= 1,\n    validation_data= valid_ds,\n    validation_steps= VAL_STEPS,\n    callbacks= [tensorboard_cb]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T15:34:46.235348Z","iopub.execute_input":"2026-02-10T15:34:46.236028Z","iopub.status.idle":"2026-02-10T16:21:31.130889Z","shell.execute_reply.started":"2026-02-10T15:34:46.236002Z","shell.execute_reply":"2026-02-10T16:21:31.130102Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\nINFO:tensorflow:Collective all_reduce tensors: 91 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Collective all_reduce IndexedSlices: 1 all_reduces, num_devices =2, group_size = 2, implementation = CommunicationImplementation.NCCL\n\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2779s\u001b[0m 910ms/step - loss: 4.6094 - perplexity: 506.7357 - val_loss: 5.4878 - val_perplexity: 260.4999\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"test_loss, test_perplexity = model.evaluate(test_ds)\nprint(f'{test_loss = }\\n{test_perplexity = }')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T16:21:31.134578Z","iopub.execute_input":"2026-02-10T16:21:31.134868Z","iopub.status.idle":"2026-02-10T16:23:01.409715Z","shell.execute_reply.started":"2026-02-10T16:21:31.134830Z","shell.execute_reply":"2026-02-10T16:23:01.409085Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 318ms/step - loss: 5.3643 - perplexity: 237.5656\ntest_loss = 5.455310821533203\ntest_perplexity = 263.75555419921875\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"manager.save()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T16:23:01.410590Z","iopub.execute_input":"2026-02-10T16:23:01.410818Z","iopub.status.idle":"2026-02-10T16:23:02.234293Z","shell.execute_reply.started":"2026-02-10T16:23:01.410798Z","shell.execute_reply":"2026-02-10T16:23:02.233547Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoints/ckpt-2'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import subprocess\n\nsubprocess.run(['zip', '-r', 'working_dir.zip', '/kaggle/working'], stdout= subprocess.DEVNULL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-10T16:23:02.235770Z","iopub.execute_input":"2026-02-10T16:23:02.236072Z","iopub.status.idle":"2026-02-10T16:23:43.436660Z","shell.execute_reply.started":"2026-02-10T16:23:02.236049Z","shell.execute_reply":"2026-02-10T16:23:43.436039Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CompletedProcess(args=['zip', '-r', 'working_dir.zip', '/kaggle/working'], returncode=0)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}